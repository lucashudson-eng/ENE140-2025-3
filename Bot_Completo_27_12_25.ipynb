{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bot Classificador - Telegram"
      ],
      "metadata": {
        "id": "dyolcyliol4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg -y\n",
        "!pip install openai-whisper\n",
        "!pip install telebot\n",
        "!pip install openai-whisper\n",
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VoniQloFtiRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bibliotecas usadas:"
      ],
      "metadata": {
        "id": "-sN0DSiryrXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import telebot\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa\n",
        "import whisper\n",
        "import csv\n",
        "import zipfile\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import random\n",
        "import time\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np # Added for image processing\n",
        "import cv2"
      ],
      "metadata": {
        "id": "QyTaLJx_tIHJ",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifica√ß√£o do √°udio:"
      ],
      "metadata": {
        "id": "GWgxfryNo7Ng"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M_dfEyimokKM"
      },
      "outputs": [],
      "source": [
        "class ClassificadorAudio:\n",
        "    def __init__(self):\n",
        "        print(\"Carregando YAMNet...\")\n",
        "        self.model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "        class_map_path = self.model.class_map_path().numpy().decode('utf-8')\n",
        "        self.class_names = self._ler_labels(class_map_path)\n",
        "\n",
        "    def _ler_labels(self, path):\n",
        "        classes = []\n",
        "        with tf.io.gfile.GFile(path) as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for row in reader:\n",
        "                classes.append(row['display_name'])\n",
        "        return classes\n",
        "\n",
        "    def identificar_som(self, arquivo_memoria):\n",
        "        arquivo_memoria.seek(0)\n",
        "        audio, sr = librosa.load(arquivo_memoria, sr=16000, mono=True)\n",
        "        scores, _, _ = self.model(audio)\n",
        "        media_scores = tf.reduce_mean(scores, axis=0)\n",
        "        idx_max = tf.argmax(media_scores)\n",
        "        return self.class_names[idx_max], media_scores[idx_max].numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Transcri√ß√£o de √°udio:"
      ],
      "metadata": {
        "id": "OnVxO_b0TL_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranscritorWhisper:\n",
        "    def __init__(self):\n",
        "        modelo = input(\"Modelo do Whisper (large/base):\")\n",
        "        print(f\"Carregando Whisper (modelo {modelo})...\")\n",
        "        self.model = whisper.load_model(modelo)\n",
        "\n",
        "    def transcrever(self, arquivo_memoria):\n",
        "        arquivo_memoria.seek(0)\n",
        "        audio, sr = librosa.load(arquivo_memoria, sr=16000)\n",
        "        resultado = self.model.transcribe(audio=audio, fp16=False)\n",
        "        arquivo_memoria.close()\n",
        "        return resultado['text']"
      ],
      "metadata": {
        "id": "V4lf2lFJRw2j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifica√ß√£o da imagem:"
      ],
      "metadata": {
        "id": "3Zq0SX7PjXtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificadorImagem:\n",
        "    def __init__(self):\n",
        "        print(\"Carregando YOLOv8n.pt...\")\n",
        "        self.model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "    def classificar_imagem(self, arquivo_memoria):\n",
        "        # Check if input is BytesIO or path string\n",
        "        if isinstance(arquivo_memoria, io.BytesIO):\n",
        "            file_bytes = np.asarray(bytearray(arquivo_memoria.read()), dtype=np.uint8)\n",
        "            image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)\n",
        "        elif isinstance(arquivo_memoria, str):\n",
        "            image = cv2.imread(arquivo_memoria)\n",
        "        else:\n",
        "            return \"Erro: Formato de entrada de imagem n√£o suportado.\", \"\"\n",
        "\n",
        "\n",
        "        if image is None:\n",
        "              return \"Erro ao carregar a imagem.\", \"\" # Return two values for consistency\n",
        "\n",
        "        # Est√° executando o yolo\n",
        "        result = self.model(image)\n",
        "\n",
        "        if len(result[0].boxes) == 0:\n",
        "              return image, \"Nenhum objeto detectado.\" # Return image and caption\n",
        "\n",
        "        # Nomes das classes j√° presentes no yolo\n",
        "        name_class = result[0].names\n",
        "\n",
        "        caption_parts = []\n",
        "        # Esse loop passa por cada parte do yolo j√° treinasdo e mostra o resultado da an√°lise\n",
        "        for box in result[0].boxes:\n",
        "          class_id = int(box.cls)\n",
        "          confidence = float(box.conf) * 100\n",
        "\n",
        "          # Desenvolvendo o comportamento da bounding box\n",
        "          x1, y1, x2, y2 = map(int, box.xyxy[0])   # bounding box\n",
        "\n",
        "          # desenha a bounding box (vermelha)\n",
        "          cv2.rectangle(\n",
        "            image,\n",
        "              (x1, y1),\n",
        "              (x2, y2),\n",
        "              (0, 0, 255), # vermelho (BGR)\n",
        "              2\n",
        "          )\n",
        "          # Desenha o texto na imagem\n",
        "          cv2.putText(\n",
        "            image,\n",
        "              f\"{name_class[class_id]} {confidence:.1f}%\",\n",
        "              (x1, max(y1 - 30, 40)),\n",
        "              cv2.FONT_HERSHEY_SIMPLEX,\n",
        "              0.6,\n",
        "              (0, 0, 255),\n",
        "              2\n",
        "          )\n",
        "\n",
        "          # Imprime no prompt\n",
        "          detected_info = (\n",
        "              f\"Classe: {name_class[class_id]} | \"\n",
        "              f\"Confian√ßa: {confidence:.2f}% | \"\n",
        "              f\"Box: ({x1}, {y1}, {x2}, {y2})\"\n",
        "          )\n",
        "          caption_parts.append(f\"{name_class[class_id]} ({confidence:.1f}%)\")\n",
        "\n",
        "        legenda = \"Objetos detectados: \" + \", \".join(caption_parts) if caption_parts else \"Nenhum objeto detectado.\"\n",
        "        return image, legenda"
      ],
      "metadata": {
        "id": "w55KzVzujcLe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base do Bot"
      ],
      "metadata": {
        "id": "fGDGU5966tZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BotTelegram:\n",
        "    def __init__(self, token, **kwargs): # Accept kwargs for cooperative inheritance\n",
        "        self.__token = token  # Atributo privado\n",
        "        self.bot = telebot.TeleBot(self.__token)\n",
        "        # No super().__init__(**kwargs) here, as object (its ultimate base) doesn't take kwargs.\n",
        "    def _configurar_handlers(self):\n",
        "\n",
        "        @self.bot.message_handler(commands=['start'])\n",
        "        def start(message):\n",
        "            nome = message.from_user.first_name\n",
        "            self.bot.reply_to(message, f\"Ol√°, {nome}! Sou um BOT criado para transcrever seus √°udios e classificar √°udios e imagens.\")\n",
        "\n",
        "        @self.bot.message_handler(commands=['ajuda'])\n",
        "        def ajuda(message):\n",
        "            self.bot.reply_to(message, \"Experimente me enviar uma imagem ou √°udio e eu vou tentar classific√°-lo.\")\n",
        "\n",
        "        @self.bot.message_handler(content_types=['video', 'sticker', 'animation', 'video_note', 'document', 'poll'])\n",
        "        def responder(message):\n",
        "            self.bot.reply_to(message, \"Desculpe, n√£o trabalhamos com esse tipo de arquivo. Tente nos enviar uma imagem ou um √°udio.\")\n",
        "\n",
        "        @self.bot.message_handler(content_types=['text'])\n",
        "        def texto(message):\n",
        "            self.bot.reply_to(message, \"Desculpe, n√£o consigo entender o que voc√™ diz. N√£o sou adaptado para compreender e responder textos. Eu apenas consigo classificar e/ou transcrever imagens e √°udios que voc√™ me enviar.\")\n",
        "\n",
        "    def executar(self):\n",
        "        print(\"Bot Online...\")\n",
        "        self.bot.infinity_polling()"
      ],
      "metadata": {
        "id": "kVGPBFY_6pVV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bot para o √°udio:"
      ],
      "metadata": {
        "id": "uPD0sLmI7LYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BotAudio(BotTelegram):\n",
        "    def __init__(self, token, motor_som, motor_texto, **kwargs):\n",
        "        super().__init__(token=token, **kwargs) # Pass token as keyword argument\n",
        "\n",
        "        self.classificador_audio = motor_som\n",
        "        self.transcritor = motor_texto\n",
        "        # Handlers are configured by calling this method (which calls super()._configurar_handlers())\n",
        "\n",
        "    def _configurar_handlers_audio(self):\n",
        "        super()._configurar_handlers()\n",
        "        @self.bot.message_handler(content_types=['voice', 'audio'])\n",
        "        def tratar_audio(message):\n",
        "            status = self.bot.reply_to(message, \"‚è≥ Analisando √°udio...\")\n",
        "            try:\n",
        "                file_info = self.bot.get_file(message.voice.file_id if message.voice else message.audio.file_id)\n",
        "                downloaded_file = self.bot.download_file(file_info.file_path)\n",
        "                audio_ram = io.BytesIO(downloaded_file)\n",
        "\n",
        "                # Reset stream position before classification and transcription\n",
        "                audio_ram.seek(0)\n",
        "                classe, confianca = self.classificador_audio.identificar_som(audio_ram)\n",
        "                audio_ram.seek(0) # Reset again for transcription\n",
        "\n",
        "                resposta = f\"‚úÖ Som identificado: {classe} ({confianca:.2%})\\n\"\n",
        "\n",
        "                if \"Speech\" in classe or \"Conversation\" in classe:\n",
        "                    self.bot.edit_message_text(resposta + \"üéôÔ∏è Transcrevendo...\", message.chat.id,\n",
        "                                               status.message_id)\n",
        "                    texto = self.transcritor.transcrever(audio_ram)\n",
        "                    resposta += f\"\\nüìù Transcri√ß√£o: {texto}\"\n",
        "\n",
        "                self.bot.edit_message_text(resposta, message.chat.id, status.message_id, parse_mode=\"Markdown\")\n",
        "\n",
        "            except Exception as e:\n",
        "                resposta += f\"\\nErro: {str(e)}\"\n",
        "                self.bot.edit_message_text(resposta, message.chat.id, status.message_id, parse_mode=\"Markdown\")\n",
        "\n",
        "            finally:\n",
        "                if 'audio_ram' in locals() and not audio_ram.closed:\n",
        "                    audio_ram.close()"
      ],
      "metadata": {
        "id": "YnVFN_hh7PiF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bot para a imagem:"
      ],
      "metadata": {
        "id": "v-aK3YTTjegp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BotImagem(BotTelegram):\n",
        "    def __init__(self, token, motor_imagem, **kwargs):\n",
        "        super().__init__(token=token, **kwargs) # Pass token as keyword argument\n",
        "        self.classificador_imagem = motor_imagem\n",
        "\n",
        "    def _configurar_handlers_image(self):\n",
        "        super()._configurar_handlers() # Call parent's general handlers\n",
        "\n",
        "        @self.bot.message_handler(content_types=['photo'])\n",
        "        def tratar_foto(message):\n",
        "            status = self.bot.reply_to(message, \"‚è≥ Imagem recebida. Vamos tentar classific√°-la.\\n\\nBaixando imagem...\")\n",
        "\n",
        "            file_id = message.photo[-1].file_id # Pega a maior resolu√ß√£o\n",
        "            file_info = self.bot.get_file(file_id)\n",
        "            downloaded_file = self.bot.download_file(file_info.file_path)\n",
        "\n",
        "            imagem_ram = io.BytesIO(downloaded_file)\n",
        "\n",
        "            self.bot.edit_message_text(\"Download conclu√≠do.\\n\\nClassificando imagem...\", message.chat.id, status.message_id)\n",
        "\n",
        "            imagem_resultante, legenda = self.classificador_imagem.classificar_imagem(imagem_ram)\n",
        "            imagem_ram.close()\n",
        "\n",
        "            self.bot.delete_message(message.chat.id, status.message_id)\n",
        "\n",
        "            if isinstance(imagem_resultante, str): # Error message from classifier\n",
        "                self.bot.send_message(message.chat.id, imagem_resultante)\n",
        "            else:\n",
        "                # Convert numpy array to bytes for sending\n",
        "                success, encoded_image = cv2.imencode('.png', imagem_resultante)\n",
        "                if success:\n",
        "                    photo_bytes = io.BytesIO(encoded_image.tobytes())\n",
        "                    self.bot.send_photo(message.chat.id, photo_bytes, caption=legenda)\n",
        "                    photo_bytes.close()\n",
        "                else:\n",
        "                    self.bot.send_message(message.chat.id, \"Erro ao converter imagem classificada para envio.\")"
      ],
      "metadata": {
        "id": "5xf4caZ7j52d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BotAdmin"
      ],
      "metadata": {
        "id": "43nRJjUloBTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BotAdmin(BotAudio, BotImagem):\n",
        "    def __init__(self, token, motor_som, motor_texto, motor_imagem, **kwargs):\n",
        "        # Pass all arguments as keyword arguments to super(), which handles MRO.\n",
        "        super().__init__(token=token, motor_som=motor_som, motor_texto=motor_texto, motor_imagem=motor_imagem, **kwargs)\n",
        "        # After all parents are initialized, configure all handlers through the MRO.\n",
        "        super()._configurar_handlers_image()\n",
        "        super()._configurar_handlers_audio()\n",
        "        super()._configurar_handlers()"
      ],
      "metadata": {
        "id": "rfPKL2y1oFNa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Execu√ß√£o:"
      ],
      "metadata": {
        "id": "5OD1rOoCpX2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    TOKEN = '7812768588:AAFyWirqLGt_B-cdMip7sWMp8n_bVBYvzyo'\n",
        "\n",
        "    # 1. Instancia as IAs primeiro\n",
        "    ia_som = ClassificadorAudio()\n",
        "    ia_texto = TranscritorWhisper()\n",
        "    ia_imagem = ClassificadorImagem()\n",
        "\n",
        "    # 2. Instancia a classe filha, que j√° configura a classe m√£e internamente\n",
        "    # Pass all arguments as keyword arguments\n",
        "    meu_bot = BotAdmin(token=TOKEN, motor_som=ia_som, motor_texto=ia_texto, motor_imagem=ia_imagem)\n",
        "\n",
        "    # 3. Inicia o polling\n",
        "    meu_bot.executar()"
      ],
      "metadata": {
        "id": "jwJJRZtUpUsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Whisper: Adicionei a op√ß√£o de escolha entre os modelos large e base para o operador que ir√° iniciar o bot. O modelo large √© muito preciso, mas √© lento e pesado. O google colab suporta ele no limite da mem√≥ria RAM dispon√≠vel e um bug ou recompila√ß√£o reinicia a sess√£o. O modelo base √© inferior, mas √© significativamente mais leve e veloz."
      ],
      "metadata": {
        "id": "GzFEbcg2wjSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Falta organizar melhor as intera√ß√µes do Bot com rela√ß√£o √†s mensagens do usu√°rio, como quando envia uma mensagem aleat√≥ria, ou um arquivo n√£o compat√≠vel. Al√©m disso, as din√¢micas de edi√ß√£o de mensagem do TeleBot tornam a intera√ß√£o mais din√¢mica, mas seria bom dar uma revisada para ficar visualmente mais agrad√°vel em tudo."
      ],
      "metadata": {
        "id": "XNuXwBoULFv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Falta fazer a documenta√ß√£o tamb√©m."
      ],
      "metadata": {
        "id": "S0iWIN1ZLrKE"
      }
    }
  ]
}