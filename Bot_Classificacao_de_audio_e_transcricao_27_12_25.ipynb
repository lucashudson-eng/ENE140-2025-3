{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Resumo de comandos, fun√ß√µes e c√≥digos √∫teis para o trabalho"
      ],
      "metadata": {
        "id": "dyolcyliol4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg -y\n",
        "!pip install openai-whisper\n",
        "!pip install telebot\n",
        "!pip install openai-whisper\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VoniQloFtiRi",
        "outputId": "75c3e340-c746-46ae-8b29-b94fe7a491d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.\u001b[0m\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connected\u001b[0m\r                                                                               \rHit:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 3,917 B in 1s (2,759 B/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "6 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.5.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
            "Requirement already satisfied: telebot in /usr/local/lib/python3.12/dist-packages (0.0.5)\n",
            "Requirement already satisfied: pyTelegramBotAPI in /usr/local/lib/python3.12/dist-packages (from telebot) (4.29.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from telebot) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->telebot) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->telebot) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->telebot) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->telebot) (2025.11.12)\n",
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.9.0+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.5.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eRtUiC93TTSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Bibliotecas usadas:"
      ],
      "metadata": {
        "id": "-sN0DSiryrXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import telebot\n",
        "import io\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import librosa\n",
        "import whisper\n",
        "import csv"
      ],
      "metadata": {
        "id": "QyTaLJx_tIHJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classifica√ß√£o do √°udio:"
      ],
      "metadata": {
        "id": "GWgxfryNo7Ng"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M_dfEyimokKM"
      },
      "outputs": [],
      "source": [
        "class ClassificadorAudio:\n",
        "    def __init__(self):\n",
        "        print(\"Carregando YAMNet...\")\n",
        "        self.model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
        "        class_map_path = self.model.class_map_path().numpy().decode('utf-8')\n",
        "        self.class_names = self._ler_labels(class_map_path)\n",
        "\n",
        "    def _ler_labels(self, path):\n",
        "        classes = []\n",
        "        with tf.io.gfile.GFile(path) as f:\n",
        "            reader = csv.DictReader(f)\n",
        "            for row in reader:\n",
        "                classes.append(row['display_name'])\n",
        "        return classes\n",
        "\n",
        "    def identificar_som(self, arquivo_memoria):\n",
        "        arquivo_memoria.seek(0)\n",
        "        audio, sr = librosa.load(arquivo_memoria, sr=16000, mono=True)\n",
        "        scores, _, _ = self.model(audio)\n",
        "        media_scores = tf.reduce_mean(scores, axis=0)\n",
        "        idx_max = tf.argmax(media_scores)\n",
        "        return self.class_names[idx_max], media_scores[idx_max].numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Transcri√ß√£o de √°udio:"
      ],
      "metadata": {
        "id": "OnVxO_b0TL_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TranscritorWhisper:\n",
        "    def __init__(self):\n",
        "        print(\"Carregando Whisper (modelo large)...\")\n",
        "        self.model = whisper.load_model(\"large\")\n",
        "\n",
        "    def transcrever(self, arquivo_memoria):\n",
        "        arquivo_memoria.seek(0)\n",
        "        audio, sr = librosa.load(arquivo_memoria, sr=16000)\n",
        "        resultado = self.model.transcribe(audio=audio, fp16=False)\n",
        "        arquivo_memoria.close()\n",
        "        return resultado['text']"
      ],
      "metadata": {
        "id": "V4lf2lFJRw2j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Base do Bot"
      ],
      "metadata": {
        "id": "fGDGU5966tZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BotTelegram:\n",
        "    def __init__(self, token):\n",
        "        self.__token = token  # Atributo privado\n",
        "        self.bot = telebot.TeleBot(self.__token)\n",
        "    def _configurar_handlers(self):\n",
        "\n",
        "        @self.bot.message_handler(commands=['start'])\n",
        "        def start(message):\n",
        "            nome = message.from_user.first_name\n",
        "            self.bot.reply_to(message, f\"Ol√°, {nome}! Sou um BOT criado para transcrever seus √°udios e classificar √°udios e imagens.\")\n",
        "\n",
        "        @self.bot.message_handler(commands=['ajuda'])\n",
        "        def ajuda(message):\n",
        "            self.bot.reply_to(message, \"Experimente me enviar uma imagem ou √°udio e eu vou tentar classific√°-lo.\")\n",
        "\n",
        "        @self.bot.message_handler(content_types=['video', 'sticker', 'animation', 'video_note', 'document', 'poll'])\n",
        "        def responder(message):\n",
        "            self.bot.reply_to(message, \"Desculpe, n√£o trabalhamos com esse tipo de arquivo. Tente nos enviar uma imagem ou um √°udio.\")\n",
        "\n",
        "        @self.bot.message_handler(content_types=['text'])\n",
        "        def texto(message):\n",
        "            self.bot.reply_to(message, \"Desculpe, n√£o consigo entender o que voc√™ diz. N√£o sou adaptado para compreender e responder textos. Eu apenas consigo classificar e/ou transcrever imagens e √°udios que voc√™ me enviar.\")\n",
        "\n",
        "    def executar(self):\n",
        "        print(\"Bot online.\")\n",
        "        self.bot.infinity_polling()"
      ],
      "metadata": {
        "id": "kVGPBFY_6pVV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bot para √°udio:"
      ],
      "metadata": {
        "id": "uPD0sLmI7LYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BotAudio(BotTelegram):\n",
        "    def __init__(self, token, motor_som, motor_texto):\n",
        "        super().__init__(token)\n",
        "\n",
        "        self.classificador = motor_som\n",
        "        self.transcritor = motor_texto\n",
        "        self._configurar_handlers()\n",
        "\n",
        "    def _configurar_handlers(self):\n",
        "        super()._configurar_handlers()\n",
        "        @self.bot.message_handler(content_types=['voice', 'audio'])\n",
        "        def tratar_audio(message):\n",
        "            status = self.bot.reply_to(message, \"‚è≥ Analisando √°udio...\")\n",
        "            try:\n",
        "                file_info = self.bot.get_file(message.voice.file_id if message.voice else message.audio.file_id)\n",
        "                downloaded_file = self.bot.download_file(file_info.file_path)\n",
        "                audio_ram = io.BytesIO(downloaded_file)\n",
        "\n",
        "                classe, confianca = self.classificador.identificar_som(audio_ram)\n",
        "                resposta = f\"‚úÖ Som identificado: {classe} ({confianca:.2%})\\n\"\n",
        "\n",
        "                if \"Speech\" in classe or \"Conversation\" in classe:\n",
        "                    self.bot.edit_message_text(resposta + \"üéôÔ∏è Transcrevendo...\", message.chat.id,\n",
        "                                               status.message_id)\n",
        "                    texto = self.transcritor.transcrever(audio_ram)\n",
        "                    resposta += f\"\\nüìù Transcri√ß√£o: {texto}\"\n",
        "\n",
        "                self.bot.edit_message_text(resposta, message.chat.id, status.message_id, parse_mode=\"Markdown\")\n",
        "\n",
        "            except Exception as e:\n",
        "                resposta += f\"\\nErro: {str(e)}\"\n",
        "                self.bot.edit_message_text(resposta, message.chat.id, status.message_id, parse_mode=\"Markdown\")\n",
        "\n",
        "            finally:\n",
        "                audio_ram.close()"
      ],
      "metadata": {
        "id": "YnVFN_hh7PiF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Execu√ß√£o:"
      ],
      "metadata": {
        "id": "5OD1rOoCpX2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    TOKEN = '7812768588:AAFyWirqLGt_B-cdMip7sWMp8n_bVBYvzyo'\n",
        "\n",
        "    # 1. Instancia as IAs primeiro\n",
        "    ia_som = ClassificadorAudio()\n",
        "    ia_texto = TranscritorWhisper()\n",
        "\n",
        "    # 2. Instancia a classe FILHA, que j√° configura o PAI internamente\n",
        "    meu_bot = BotAudio(TOKEN, ia_som, ia_texto)\n",
        "\n",
        "    # 3. Inicia o polling\n",
        "    meu_bot.executar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwJJRZtUpUsg",
        "outputId": "ae39625f-349f-4bca-d214-46d39ecee1b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando YAMNet...\n",
            "Carregando Whisper (modelo large)...\n",
            "Bot online.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-12-27 15:48:39,441 (__init__.py:1121 MainThread) ERROR - TeleBot: \"Infinity polling: polling exited\"\n",
            "ERROR:TeleBot:Infinity polling: polling exited\n",
            "2025-12-27 15:48:39,452 (__init__.py:1123 MainThread) ERROR - TeleBot: \"Break infinity polling\"\n",
            "ERROR:TeleBot:Break infinity polling\n"
          ]
        }
      ]
    }
  ]
}